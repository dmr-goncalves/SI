<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
    <title>Simbrain Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
    <link href="../../../Styles.css" rel="stylesheet" type="text/css">
</head>

<body>
    <a href="../../../SimbrainDocs.html">
        <div class="logo">
            <p><span></span>
            </p>
        </div>
    </a>
    <div id="main_docs">
        <div class="navi">
            <p><a href="../../../SimbrainDocs.html">Simbrain</a> &gt; <a href="../../Network.html">Network</a> &gt; <a href="../training.html">Training</a> &gt; LMS Iterative
            </p>
        </div>

        <h1>Least Mean Squares Iterative</h1>

        <p>The <a href="http://en.wikipedia.org/wiki/Delta_rule">Least Mean Squares</a> or LMS rule is a classic form of supervised learning, which means that the user must supply desired output values for each of a list of input values.</p>

        <p> The lms iterative trainer can be configured in the <a href="trainingDialog.html">trainer dialog</a>. It is primarily used by the <a href="../network/lmsnetwork.html">least mean square network</a> and <a href="../network/echostatenetwork.html">echo state network</a>, though it can also be used by <a href="../../Scripting.html">scripts</a> and in other ways.  The following parameter can be modified.
        </p>

        <blockquote>
            <p><span class="heading2">Learning Rate: </span>A standard learning rate. This determines how quickly synapses change. </p>
        </blockquote>

        <p class="heading">Basic operation</p>
        <p>The LMS rule works as follows. The change in a weight is equal to the product of a learning rate &#949;, the pre-synaptic source activation, and the difference between the post-synaptic activation <em>a<sub>j</sub></em> and a desired activation <em>t<sub>j</sub></em>. The error is the difference between the desired and actual activation of the target neuron.
        </p>
        <p><img src="../equations/LMSRule.png" height="54" width="203">
        </p>
        <p>Repeated application of this rule minimizes reduces mean squared error on a set of training data. </p>
        <p>This rule is also known as the "Widrow-Hoff" rule, and the "Delta Rule." Networks that use these rules are sometimes called "adalines" or "madalines" (for the multilayer case, which these networks do not currently implement). They are descendants of an early form of network studied by Rosenblatt called a "perceptron."</p>
    </div>
</body>

</html>